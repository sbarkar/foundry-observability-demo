# Foundry Observability Demo

A repository showcasing an example of how to use Microsoft Foundry to deploy a simple and compliant GenAI use case using Microsoft native tools with comprehensive observability and monitoring.

## Overview

This project demonstrates observability and monitoring best practices for GenAI applications built with Microsoft Foundry, deployed on Azure infrastructure. It includes full OpenTelemetry instrumentation, Application Insights integration, and production-ready KQL queries for monitoring.

## Architecture

This project demonstrates a full-stack observability solution with:

- **Frontend** (`web/`): Static Web App (React/Next.js) - User interface for interacting with the GenAI application
- **Backend** (`api/`): Function App (Python, Linux Consumption) - Azure Functions-based API layer with:
  - **Health Check Endpoint** (`/api/health`): No authentication required
  - **Chat Endpoint** (`/api/chat`): Entra ID JWT authentication
  - **Azure OpenAI Integration**: Uses DefaultAzureCredential for managed identity
  - **Optional RAG**: Query Azure AI Search and inject context into prompts
  - **OpenTelemetry**: Full instrumentation with Application Insights
  - **Stateless Design**: No database, metadata-only logging (no user content stored)
- **Infrastructure** (`infra/`): Bicep templates for Azure resource deployment
- **AI Services**: Azure AI Search, Microsoft Foundry
- **Observability**: Application Insights + Log Analytics Workspace with custom dashboards
- **Storage**: Azure Storage Account
- **Security**: Azure Key Vault for secrets management
- **Documentation** (`docs/`): Comprehensive observability guide with KQL queries

All resources are deployed to **Sweden Central** (except the resource group in Switzerland North).

## Key Features

- âœ… **OpenTelemetry Integration**: Full distributed tracing with hierarchical spans
- âœ… **Azure Application Insights**: Seamless telemetry export to Azure Monitor
- âœ… **RAG Observability**: Track document retrieval, context building, and vector search
- âœ… **LLM Monitoring**: Monitor token usage, latency, and model performance
- âœ… **Safety Tracking**: Monitor content safety checks and blocked outputs
- âœ… **Privacy-First**: Metadata-only logging (no raw prompts/responses)
- âœ… **KQL Dashboards**: 20+ production-ready queries for latency, costs, errors, and usage analysis
- âœ… **Entra ID Authentication**: JWT validation for secure API access
- âœ… **Infrastructure as Code**: Automated Bicep deployment

## Repository Structure

```
foundry-observability-demo/
â”œâ”€â”€ web/                        # Frontend application
â”œâ”€â”€ api/                        # Azure Functions backend
â”‚   â”œâ”€â”€ function_app.py        # Main functions app
â”‚   â”œâ”€â”€ health.py              # Health check endpoint
â”‚   â”œâ”€â”€ chat.py                # Chat endpoint with OpenAI & RAG
â”‚   â”œâ”€â”€ auth.py                # JWT validation
â”‚   â”œâ”€â”€ telemetry.py           # OpenTelemetry configuration
â”‚   â”œâ”€â”€ tests/                 # Unit tests (16 tests)
â”‚   â””â”€â”€ README.md              # Detailed API documentation
â”œâ”€â”€ infra/                      # Infrastructure as Code (Bicep)
â”‚   â”œâ”€â”€ main.bicep             # Main Bicep template
â”‚   â”œâ”€â”€ parameters.json        # Deployment parameters
â”‚   â”œâ”€â”€ deploy.sh              # Automated deployment script
â”‚   â”œâ”€â”€ .bicepconfig.json      # Bicep configuration
â”‚   â””â”€â”€ README.md              # Detailed infrastructure docs
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ observability.md       # Observability guide with KQL queries
â”‚   â””â”€â”€ README.md              # Documentation index
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â””â”€â”€ generate-env.sh        # Generate .env from deployment
â”œâ”€â”€ .env.template              # Environment variables template
â”œâ”€â”€ .gitignore                 # Git ignore patterns
â”œâ”€â”€ pyproject.toml             # Python linting configuration
â”œâ”€â”€ LICENSE                    # License file
â””â”€â”€ README.md                  # This file
```

## Getting Started

### Prerequisites

- Azure CLI installed and authenticated
- Azure subscription with appropriate permissions
- Python 3.11+
- Node.js 18+
- Azure Functions Core Tools (for local API development)
- Git

### Infrastructure Deployment

The infrastructure is deployed using Bicep templates. For detailed deployment instructions, see [infra/README.md](infra/README.md).

#### Quick Start

```bash
cd infra
./deploy.sh demo
```

Or manually:

```bash
cd infra
az deployment group create \
  --resource-group rg-foundry-demo \
  --template-file main.bicep \
  --parameters parameters.json
```

For complete documentation including:
- Step-by-step deployment guide
- Post-deployment configuration
- Manual steps for Foundry project creation
- Troubleshooting tips

See the comprehensive guide: **[infra/README.md](infra/README.md)**

## Infrastructure Resources

| Resource | Purpose | Location |
|----------|---------|----------|
| Resource Group | Container for all resources | Switzerland North |
| Static Web App | Frontend hosting | Sweden Central |
| Function App | Backend API (Python 3.11) | Sweden Central |
| Storage Account | Data storage | Sweden Central |
| Application Insights | Application monitoring | Sweden Central |
| Log Analytics | Centralized logging | Sweden Central |
| Azure AI Search | Search and vector store | Sweden Central |
| Key Vault | Secrets management | Sweden Central |

## Local Development Setup

### Backend (Azure Functions)

1. Navigate to the API directory:
   ```bash
   cd api/
   ```

2. Create a virtual environment:
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   pip install -r requirements-dev.txt  # For development tools
   ```

4. Copy the example settings file:
   ```bash
   cp local.settings.example.json local.settings.json
   ```

5. Update `local.settings.json` with your configuration (do not commit this file)

6. Run the Azure Functions locally:
   ```bash
   func start
   ```

The API will be available at `http://localhost:7071`

For detailed API documentation, see [api/README.md](api/README.md).

### Frontend

1. Navigate to the web directory:
   ```bash
   cd web/
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Run the development server:
   ```bash
   npm run dev
   ```

### Environment Variables

After infrastructure deployment, configure your local environment with the outputs:

```bash
# Get deployment outputs
az deployment group show \
  --resource-group rg-foundry-demo \
  --name main \
  --query properties.outputs
```

Or use the provided script:

```bash
./scripts/generate-env.sh
```

Key environment variables (set in `local.settings.json` for local development):

- `AZURE_OPENAI_ENDPOINT`: Your Azure OpenAI endpoint URL
- `AZURE_OPENAI_API_VERSION`: API version for Azure OpenAI
- `APPLICATIONINSIGHTS_CONNECTION_STRING`: Application Insights connection string
- `AZURE_SEARCH_ENDPOINT`: Azure AI Search endpoint
- `AZURE_KEY_VAULT_ENDPOINT`: Key Vault URI
- `STORAGE_ACCOUNT_NAME`: Storage account name

## Observability & Monitoring

### OpenTelemetry Instrumentation

The API includes comprehensive OpenTelemetry instrumentation for:

1. **Request Processing** - End-to-end request tracing with correlation IDs
2. **RAG Operations** - Document retrieval and context building metrics
3. **LLM Calls** - Token usage, latency, and model performance tracking
4. **Safety Checks** - Content safety validation and blocked content monitoring
5. **Error Tracking** - Detailed error logging with type and message

### Span Hierarchy

```
request.process (root span)
â”œâ”€â”€ request.rag_phase (if RAG enabled)
â”‚   â”œâ”€â”€ rag.retrieve
â”‚   â””â”€â”€ rag.build_context
â”œâ”€â”€ request.safety_check
â”‚   â””â”€â”€ llm.safety_check
â”œâ”€â”€ request.llm_phase
â”‚   â””â”€â”€ llm.call
â””â”€â”€ request.response_generation
```

### Custom Events

- `llm.tokens`: Token usage (prompt, completion, total)
- `llm.latency`: LLM call latency
- `rag.retrieval_complete`: RAG retrieval metrics
- `safety.check_complete`: Safety check results
- `request.complete`: Request completion summary
- `request.blocked`: Content safety blocks
- `request.error`: Error details

### Metrics

- `genai.requests.total`: Total requests processed
- `genai.errors.total`: Total errors encountered
- `genai.tokens.total`: Total tokens consumed (by type)

### KQL Queries & Dashboards

The project includes 20+ production-ready KQL queries for:
- Latency analysis (p50, p95, p99)
- Token usage and cost estimation
- RAG performance metrics
- Error tracking and debugging
- Safety check monitoring
- Request volume and success rates

See **[docs/observability.md](docs/observability.md)** for:
- Complete KQL query library
- Dashboard creation guide
- Alert setup recommendations
- Best practices and troubleshooting

### Sample Queries

**Latency P95 Over Time**
```kql
traces
| where message == "request.complete"
| extend latency_ms = todouble(customDimensions.["request.total_latency_ms"])
| summarize p95 = percentile(latency_ms, 95) by bin(timestamp, 5m)
| render timechart
```

**Token Usage Over Time**
```kql
traces
| where message == "llm.tokens"
| extend total_tokens = toint(customDimensions.["llm.usage.total_tokens"])
| summarize sum(total_tokens) by bin(timestamp, 1h)
| render timechart
```

## API Features

The backend API provides:

- âœ… Entra ID JWT authentication with configurable issuer/audience
- âœ… Azure OpenAI integration via Foundry deployment
- âœ… Optional RAG with Azure AI Search
- âœ… Correlation IDs for request tracking
- âœ… OpenTelemetry instrumentation to Application Insights
- âœ… Stateless, metadata-only logging (no user content stored)
- âœ… Comprehensive unit tests (16 tests)
- âœ… VS Code devcontainer support

## Privacy & Security

This application demonstrates **metadata-only logging**:

âœ… **Logged**: Query length, token counts, latency, model names, document counts, correlation IDs  
âŒ **NOT Logged**: Raw prompts, responses, document content, user messages

Security features:
- **Managed Identities**: Function App uses system-assigned managed identity
- **RBAC**: Least-privilege access to Key Vault and Storage
- **Secrets**: All secrets stored in Azure Key Vault
- **HTTPS Only**: All endpoints enforce HTTPS
- **TLS 1.2**: Minimum TLS version enforced
- **JWT Authentication**: Entra ID token validation for API endpoints
- **No User Content in Logs**: Metadata-only logging policy

Sensitive fields are explicitly filtered in the telemetry module.

## Development Conventions

### Code Style

**Python (API)**
- Use Python 3.11+
- Follow PEP 8 style guide
- Use `ruff` for linting and `black` for code formatting
- Line length: 88 characters

**JavaScript/TypeScript (Frontend)**
- Use ESLint for linting
- Use Prettier for code formatting
- Single quotes for strings
- 2-space indentation
- Semicolons required

### Linting

**Python**
```bash
# Run ruff linter
ruff check .

# Auto-fix issues
ruff check --fix .

# Format code with black
black .
```

**Frontend**
```bash
cd web/

# Run ESLint
npm run lint

# Auto-fix ESLint issues
npm run lint:fix

# Format with Prettier
npm run format

# Check formatting
npm run format:check
```

## Deployment

### Infrastructure (Issue #B)

âœ… **Completed** - Bicep templates for deploying Azure infrastructure to Sweden Central.

See [infra/README.md](infra/README.md) for deployment instructions.

### Function App (Issue #C)

âœ… **Completed** - Python Function App with JWT auth, OpenAI integration, and OpenTelemetry.

Required app settings are outputted by the infrastructure deployment.

### Observability (Issue #D)

âœ… **Completed** - OpenTelemetry instrumentation, Application Insights integration, and KQL dashboards.

See [docs/observability.md](docs/observability.md) for monitoring and query documentation.

### Static Web App (Issue #3)

ğŸ”œ **Coming Soon** - Frontend deployment.

Required app settings are outputted by the infrastructure deployment.

## Manual Steps

### Microsoft Foundry Project Creation

Microsoft Foundry projects require manual creation as they are in preview and don't have stable IaC providers yet.

**Steps:**
1. Navigate to Azure Portal â†’ Microsoft Foundry / Azure AI Studio
2. Create new project:
   - Name: `foundry-observability-demo`
   - Resource Group: `rg-foundry-demo`
   - Location: `Sweden Central`
3. Link deployed resources (App Insights, Storage, AI Search)

For detailed instructions, see the [Manual Steps section in infra/README.md](infra/README.md#manual-steps-required).

## Contributing

1. Follow the established code style and conventions
2. Run linters before committing code
3. Ensure all tests pass
4. Keep commits focused and atomic
5. Maintain privacy-compliant logging in all instrumentation

## License

See [LICENSE](LICENSE) file for details.

## Related Issues

- **Issue #B**: Bicep/IaC deployment âœ…
- **Issue #C**: Azure Functions API âœ…
- **Issue #D**: Observability & Monitoring âœ…
- **Issue #3**: Static Web App deployment ğŸ”œ

## Support

For deployment issues, see the troubleshooting section in [infra/README.md](infra/README.md#troubleshooting).
For observability questions, see [docs/observability.md](docs/observability.md).
